{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23aece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Computer Assignment 02\n",
    "#This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b7dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"This function builds a Dictionary of most common 3000 words from all the email content. \n",
    "#First it adds all words and symbols in the dictionary. Then it removes all non-alpha-numeric characters \n",
    "#and any single character alpha-numeric characters. After this is complete it shrinks the Dictionary \n",
    "#by keeping only most common 3000 words in the dictionary. It returns the Dictionary.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a096f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Dictionary(root_dir):\n",
    "  data_words = []\n",
    "  #this OS function is used to create a list of individual paths to each data file\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "  for email in emails:\n",
    "    with open(email) as m:\n",
    "      for line in m:\n",
    "        words = line.split()\n",
    "        data_words += words\n",
    "  print(\"all file words have been read and saved\")\n",
    "  #This line creates a counter object which is a sub object of dictionary to hold counts of each word\n",
    "  dictionary = Counter(data_words)\n",
    "  #This line makes the dictionary iteratable to be cleaned\n",
    "  uncleaned_list = list(dictionary)\n",
    "  \n",
    "  #This for loop goes through the entire set of words in the data and removes those that don't contain only\n",
    "  # letters a-z or are words that are 1 character long such as \"a\"\n",
    "  for item in uncleaned_list:\n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "  print(\"numeric strings and one character words have been removed\")\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  print(\"Dictionary has been reduced to 3000 words\")\n",
    "  return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function extracts feature columns and populates their values (Feature Matrix of 3000 comumns and rows equal to \n",
    "#the number of email files). The function also analyzes the File Names of each email file and \n",
    "#decides if it's a spam or not based on the file name. Based on this the function also creates\n",
    "#the Labelled Data Column. This function is used to extract the training dataset \n",
    "#as well as the testing dataset and returns the Feature Dataset and the Label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65556fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(mail_dir):\n",
    "  #this OS method combines file directory with the folder directory to get a list of file paths\n",
    "  emails = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  features_matrix = np.zeros((len(emails),3000)) #create blank matrix with 3000 columns and length of # of emails\n",
    "  train_labels = np.zeros(len(emails)) #creates empty array of length # of emails for spam labels\n",
    "  print(\"empty matrix and array created\")\n",
    "  count = 1;\n",
    "  docID = 0;\n",
    "  for fil in emails:\n",
    "    with open(fil) as fi: #opens each email file in the folder provided\n",
    "      for i, line in enumerate(fi):\n",
    "        if i ==2: #this starts the parsining at the 2nd line\n",
    "          words = line.split() #parses each line of the file\n",
    "          for word in words: #loops through the words in each line\n",
    "            wID = 0\n",
    "            for i, d in enumerate(dictionary): #loops through words in created training dictionary\n",
    "              if d[0] == word: #checks if word matches dictionary entry\n",
    "                wID = i\n",
    "                features_matrix[docID,wID] = words.count(word) #adds count of words for that word in matrix for that email\n",
    "      train_labels[docID] = 0; #array equals 0 if no match\n",
    "      filepathTokens = fil.split('/') #splits file name\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1] #saves last part of file name\n",
    "      if lastToken.startswith(\"spmsg\"): \n",
    "        train_labels[docID] = 1; #assigns 1 to document ID if email labeled spam\n",
    "        count = count + 1\n",
    "      docID = docID + 1 #incrememnts ID index tracker\n",
    "  print(count)\n",
    "  print(\"all emails looped through, assigned to \")\n",
    "  return features_matrix, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main program which brings in data sets of emails then processes them using the above functions.\n",
    "#Below is the call which creates the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2758148d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('order', 1414)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create partial paths for Test and Train data\n",
    "TRAIN_DIR = 'Data/train-mails'\n",
    "TEST_DIR = 'Data/test-mails'\n",
    "\n",
    "dictionary = Data_Dictionary(TRAIN_DIR)\n",
    "len(dictionary) #Test view of dictionary\n",
    "dictionary[0] #test dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ab0fecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n",
      "empty matrix and array created\n",
      "352\n",
      "all emails looped through, assigned to \n",
      "empty matrix and array created\n",
      "131\n",
      "all emails looped through, assigned to \n"
     ]
    }
   ],
   "source": [
    "#This cell uses the above function to pull the word count matrix as well as the training lables for Train and Test data\n",
    "#the training labels hold the classifications for spam or not spam (1 or 0)\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, train_labels = get_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = get_features(TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0f69141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naibe Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "Score equals 0.9653846153846154\n",
      "Predicted sample: [1. 0. 0. 0. 1. 1. 1. 0. 1. 0.]\n",
      "Actual sample: [1. 0. 0. 0. 1. 1. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#This section initiates a Naive Bayes model then uses the training emails to train and produces an accuracy score\n",
    "#based on the test emails\n",
    "model = GaussianNB()\n",
    "\n",
    "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
    "model.fit(features_matrix, train_labels)\n",
    "print (\"Training completed\")\n",
    "print (\"testing trained model to predict Test Data labels\")\n",
    "predicted_labels = model.predict(test_features_matrix)\n",
    "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "print (\"Score equals\" ,accuracy_score(test_labels, predicted_labels))\n",
    "print(\"Predicted sample:\" , predicted_labels[0:10])\n",
    "print(\"Actual sample:\", test_labels[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2bb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
